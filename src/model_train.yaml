log_file : "../log/model_train.log"
json_result: "../log/result.json"

# max_ins: 10000   # debug，最多读多少数据
train_files:  # 只读第一个
  # 全量股票
  - ../training_data/data.daily.20240308_1905
  - ../training_data/data.daily.20240228_0120
  # - ../training_data/data.daily.20240120_2111  #ETF

#预处理instance: 处理label, 过滤fid等
train_data:
  train_ins_percent: 0.8          # 训练集占比(优先于下面这个参数)
  filters: 
    enable: true
    only_etf: false
    valid_tscode : 
      enable : true
      regexp: "^[036]0"             # [正则]创业板: ^30; 主板: ^[06]0 科创板: ^68
    fid_filter:
      enable: false
      fids:
        - 958543753377806055 # 过滤掉平均跌幅2%的FID
        - 967566788535408665
        - 964283573987336748
        - 957627231141167737
        - 960528837522894319
        # v2
        - 39809429394224871
        - 74921704176550521
        - 75838226413188839
        - 81578047022719532
        - 73256294007194698
        - 92936102686032505
        - 99592445532201516
        - 91270692516676682
        - 928254776968372780
        - 938942996155189327
        - 973976219481293898
  # validate_date : "20220101"      # 验证集: 没有label且时间在这个后面
  label:
    args: 
      # key : next_3d_7d_mean_price
      key : next_7d_14d_mean_price
  min_fid_occurrence : 0    # 每个fid最少出现几次，低于这个次数，程序直接退出报错
  debug:                 # debug 函数
    fid_whitelist:                # 要debug的fid, 训练的时候也只会训练这些
      # - 1444932513133819623
      # - 1444015990897181305
      # - 1450672333743350316
      # - 1453955548291422233
    slot_whitelist: 
      # - 1
      # - 2
      # - 3
      # - 135
      # - 136 
      # - 137
      # - 49
      # - 50
      # - 51
      # - 52 
      # - 53
      # - 54
    slot_blacklist:
      # - 8
      # - 9 
      # - 10
      # - 82
      # - 83
      # - 11
      # - 230
      # - 231
      # - 232
      # - 233
      # - 234
      # - 240
      # - 241
      # - 242
      # - 243
      # - 244
# label改成分天算thre: (1) min_3d_price去掉 (2) raw_label -date2thre (3) binarize = 0.0

model: 
  # load_model : true
  label:
    binarized: None
    # binarized: date_threshold
  loss_type: distill
  # loss_type: mse
  # global_bias : True
  optimizer : 
    # type: AdagradOptimizer
    # type: MomentumOptimizer
    # momentum : 0.9       # 动量

    type: GradientDescentOptimizer  # 效果最好
  learning_rate: 0.001
  mini_batch:
    batch_size: 1000
    epoch : 50000
  bias_nn_dims: [16]
  bias_attention: False
  # dense_30d: True
# 调参经验： 
#  1. learning rate (随着特征增加，原来适合的lr可能变得不适合)
#      1e-2/1e-3: 太高了，直接学飞
#      1e-4: 0.037
#      1e-4: 0.085 会导致稀疏特征学得慢
#  2. l2_lambda (看着没什么用)
#      0 :    diff = 0.025
#      1e-3 : diff = 0.035
#      1e-4 : diff = 0.032
#      1e-5 : diff = 0.042
#  3. 有无global_bias diff 0.03 vs 0.02
#  4. adagrad: 学习率要调整为0.01, 但是扔没有明显收益
